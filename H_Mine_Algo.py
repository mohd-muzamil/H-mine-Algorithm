# Research Paper implemented in this Project:
# Title: "H-mine: hyper-structure mining of frequent patterns in large databases"
# Link: https://ieeexplore.ieee.org/document/989550

# Implementation of  H-mine(mem) Algorithm for generating Frequent itemsets in Input Dataset.

# Import necessary pyhton modules
import math
import itertools
import csv
import sys
import time
# import os
# import psutil


# This function is used to trigger the algorithm from interactive python shell after importing this module.
# This is also called using our script "Project_Main.py".
def runHmine(input_file, output_file, min_support):

    if min_support <= 0: #checking for valid value of min_support
        sys.exit("Min_support cannot be less than or equal to 0")

    print("Data Mininging begins using H-mine algorithm...")
 
    # The input file passed to this algorithm is read assuming that data elements are space " " separated
    with open(input_file,'r',encoding='utf-8-sig') as input:
        reader_obj = csv.reader(input, delimiter=" ")
        datalist=[];
        for line in reader_obj:
            datalist.append(line[:-1])

    transactionCount = len(datalist)                            #Total Transaction Count in the Input dataset
    
    # The minimum support is calculated using the ceil function. 
    # min_support which is passed to this algorithm is in precentage(%). This is converted to number of transactions.
    minSupport = math.ceil(min_support * transactionCount)
    out_frequents_items = []                # Frequent Items generated by H-Mine are appended one by one to this list
    itemsetBuffer = [None] * 200            # This buffer variable is used to store the Items under recursion to generate the final frequent-itemset
    mapItemToSupport = {}   #This Dictionary will be used to store the support values of all the unique items in input dataset
    mapItemRow = {} #This Dict will help us build the H-Struct table.


    # This function creates output_file when program is run for first time. 
    # Later this is used to truncate the data so that fresh results can be stored in output file
    def empty_file():
        with open(output_file, 'w') as f_output:
            f_output.close()
        file = open(output_file,"r+")
        file.truncate(0)
        file.close()

    # This function is used to write the data into output_file
    def write_into_file(string):
        with open(output_file, 'a') as f_output:
            f_output.write(string+"\n")
            f_output.close()

     # This function is used to generate frequent items using values in itemsetBuffer and prefixlen and apped that value to output list out_frequents_items
    def writeOut (prefix, prefixlen, item, support):
        freq = []
        for val in range(prefixlen):
            freq.append(prefix[val])
        freq.append(item)

        out_str = ""
        for val in freq:
            out_str += val + ","

        temp = f'{out_str[:-1]} # Supp: {support}' #Temp has the fequent itemset for current iteration
        out_frequents_items.append(temp)           #Appending temp values to Output list out_frequents_items

    # Creating Class called Row to store the itemsets objects in form item, support of item, item pointer
    class Row:
        def __init__(self, item):
            self.item = item
            self.support = 0
            self.pointer = []


    #Building mapItemToSupport Dictionary with Unique Items in input dataset and it's support value
    for tran in datalist:
        for item in tran:
            if item not in mapItemToSupport.keys(): 
                mapItemToSupport[item] = 1
            else : 
                mapItemToSupport[item] += 1

    rowlist=[]      #This acts as a Header table storing the list of row objects

    for keys in mapItemToSupport.keys():
        if mapItemToSupport[keys] >= minSupport:
            rowItem = Row(keys);
            rowItem.support = mapItemToSupport[keys]
            rowlist.append(rowItem)
            mapItemRow[keys] = rowItem

    # This is used to find the frequent-item cell of the database.
    # All the other frequent-itemsets will be found using this cell.

    cell = []   #This variable stores all the frequent projections in all the transactions seperated by -1

    flist = sorted(mapItemRow.keys()) # f-list of frequent itemsets in sorted order

    idx = 0
    #This loop is used to append frequent projections in Cell list and append their respective pointers in mapItemRow dictionary 
    for tran in datalist:
        temp=[]
        for item in tran:
            if item in flist:
                if item not in temp: # checking double occurences in the list
                    temp.append(item)

        if temp:
            temp = sorted(temp, key = lambda x: mapItemToSupport[x])
            for x in temp:
                cell.append(x)
                mapItemRow[x].pointer.append(idx)
                idx += 1
            cell.append(-1)
            idx += 1


    # This function impletements this logic for H-mine algorithm and is called recursively 
    def hmine(prefix=[], prefixlen=0, rowlist=[]):

        for row in rowlist: #Traversing the header table (rowlist)
            newRowlist=[]
            mapItemRow.clear()

            #traversing all pointers of row object in row list and building new recursive sub-level header
            for pointer in row.pointer:
                pointer+=1

                if cell[pointer]==-1:
                    continue;

                #Generating the row objects and incresing the support for all the unique items in row objects    
                while cell[pointer] != -1 :
                    item=cell[pointer]
                    if mapItemRow.get(item,None) == None :
                        rowItem = Row(item)
                        rowItem.support = 1
                        rowItem.pointer.append(pointer)
                        mapItemRow[item] = rowItem

                    else:    
                        mapItemRow[item].support += 1
                        mapItemRow[item].pointer.append(pointer)

                    pointer += 1

            #Appending only those row objects which have support greater than min_support
            for entry in mapItemRow:
                currentRow = mapItemRow[entry]
                if currentRow.support >= minSupport:
                    newRowlist.append(currentRow)

            #Calling writeOut function to generate the frequent items and store in output list
            writeOut(itemsetBuffer, prefixlen, row.item, row.support)

            #Sorting newRowlist in lexical order
            if len(newRowlist) != 0 :
                newRowlist = sorted(newRowlist, key = lambda x : x.support)


                #Store current row item in buffer before recursion so that it can be used to build the frequent itemset values    
                itemsetBuffer[prefixlen] = row.item

                hmine(prefix, prefixlen+1, newRowlist)      #recursively calling Hmine algorithm


    hmine(itemsetBuffer, 0, rowlist)  #Calling Hmine algorithm for first time using empty Buffer and 0 as prefixlength and initial value of rowlist Header.

    itemset_count = len(out_frequents_items) # Total number of frequent_items for given input_file dataset

    # Below code is used to truncate the output file and write the Frequent_itemsets generated into the output file
    empty_file()  
    write_into_file(f'Input DataSet used is : {input_file}')
    write_into_file(f'output_file is : {output_file}')
    write_into_file(f'min_sup is : {minSupport}\n')
    write_into_file(f'Frequent_Itemsets, Support')
    [write_into_file(out) for out in sorted(out_frequents_items)]
    write_into_file(f'\nTotal Frequent Itemset Count = {itemset_count}')
    print(f'Data Mining completed using H-Mine algorithm for "{input_file}" dataset\nFrequent Itemsets stored in "{output_file}"')
    print("End of Program")
    

# Below Code returns the memory usage of this algorithm. This section was used to generate metrics used for experimental analysys.
# processid = os.getpid()
# process = psutil.Process(processid)
# memoryUse = process.memory_info()
# return memoryUse.rss